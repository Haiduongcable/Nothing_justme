{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import json \n",
    "import os\n",
    "import time \n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from faiss import write_index, read_index\n",
    "from pyvi.ViTokenizer import tokenize\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils import generate_prompt_based_on_train, get_final_choices, init_bm25, generate_prompt_based_on_train_bm25\n",
    "from preprocess.process_numeric_math import process_numeric_math\n",
    "from preprocess.process_unit_math import preprocess_unit_math\n",
    "from config import config\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if config[\"DELOY_KAGGLE\"]:\n",
    "    PATH_TRAIN_CSV = \"/kaggle/input/zalo-ai-2023-elementaty-maths-solving/zalo_ai_2023_elementary_maths_solving/math_train.json\"\n",
    "    PATH_TEST_CSV = \"/kaggle/input/zalo-ai-2023-elementaty-maths-solving/zalo_ai_2023_elementary_maths_solving/math_test.json\"\n",
    "else:\n",
    "    PATH_TRAIN_CSV = \"/data/math_train.json\"\n",
    "    PATH_TEST_CSV = \"/data/math_test.json\"\n",
    "\n",
    "\n",
    "    \n",
    "if config[\"USE_MODEL\"]:\n",
    "    # nf4_config = BitsAndBytesConfig(\n",
    "    #         load_in_4bit=True,\n",
    "    #         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    #         bnb_4bit_use_double_quant=True,\n",
    "    #         bnb_4bit_quant_type='nf4'\n",
    "    #     )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-14B\", trust_remote_code=True, cache_dir='pretrained/pretrained_tokenizer')\n",
    "    max_memory_mapping = {0: \"16GB\"}\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-14B\",\n",
    "                                                # quantization_config = nf4_config,\n",
    "                                                load_in_4bit=True,\n",
    "                                                device_map=\"auto\",\n",
    "                                                trust_remote_code=True,\n",
    "                                                max_memory=max_memory_mapping, cache_dir='pretrained/pretrained_model').eval()\n",
    "    \n",
    "\n",
    "prefix_prompt = '''\n",
    "You are a virtual assistant capable of answering math questions honestly and accurately, without fabricating additional content.\n",
    "Based on the following multiple choice questions, let's think step by step, come up with a solution and choose the correct answer.\n",
    "\n",
    "Câu hỏi:\n",
    "Một người bán hàng bỏ ra 80,000 đồng tiền vốn và bị lỗ 6%. Để tính số tiền lỗ ta phải tính?\n",
    "A. 80,000 : 6\n",
    "B. 80,000 x 6\n",
    "C. 80,000 : (6 x 100)\n",
    "D. (80,000 x 6) : 100\n",
    "Solution: Theo đề bài, số tiền lỗ bằng 6% của 80 000 đồng . Để tìm số tiền lỗ ta có thể lấy 80 000 chia cho 100 rồi nhân với 6 (tức là 80 000 : 100 × 6) hoặc lấy 80000 nhân với 6 rồi chia cho 100 (tức là 80 000 × 6 : 100).\n",
    "Correct answer: D. (80,000 x 6) : 100\n",
    "\n",
    "Câu hỏi:\n",
    "8 dm2 24 cm2 = ……… dm2. Số thích hợp điền vào chỗ chấm là?\n",
    "A. 824\n",
    "B. 82,4\n",
    "C. 8,24\n",
    "D. 0,824\n",
    "Solution: Ta có 24 cm2 = 0,24 dm2 Vậy 8 dm2 24 cm2 = 8,24 dm2.\n",
    "Correct answer: C. 8,24\n",
    "\n",
    "Câu hỏi:\n",
    "10% của 11,5m2 là?\n",
    "A. 10,15dm2\n",
    "B. 1,5m2\n",
    "C. 15,5m2\n",
    "D. 1,15m2\n",
    "Solution: 10% của 11,5m2 là: 11,5 ${\\\\times}$ 10 : 100 = 1,15 (m2).\n",
    "Correct answer: D. 1,15m2\n",
    "\n",
    "Câu hỏi:\n",
    "10% của 11,5m2 là?\n",
    "A. 10,15dm2\n",
    "B. 1,5m2\n",
    "C. 15,5m2\n",
    "D. 1,15m2\n",
    "Solution: 10% của 11,5m2 là: 11,5 ${\\\\times}$ 10 : 100 = 1,15 (m2).   \n",
    "Correct answer: D. 1,15m2\n",
    "'''\n",
    "\n",
    "file_test = open(PATH_TEST_CSV, 'r')\n",
    "data_test = json.load(file_test)\n",
    "file_train = open(PATH_TRAIN_CSV, 'r')\n",
    "data_train = json.load(file_train)\n",
    "bm25_index, l_data_with_explanation = init_bm25(data_train[\"data\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_predicted_time = []\n",
    "l_submit_ids = []\n",
    "l_submit_answers = []\n",
    "for idx, item in tqdm(enumerate(data_test[\"data\"])):\n",
    "    id = item[\"id\"]\n",
    "    t1 = time.time()\n",
    "    try:\n",
    "        status, answer_responce = preprocess_unit_math(item)\n",
    "        if status:\n",
    "            l_submit_ids.append(id)\n",
    "            l_submit_answers.append(answer_responce)\n",
    "            t2 = time.time()\n",
    "            predicted_time = int(t2*1000 - t1*1000)\n",
    "            l_predicted_time.append(predicted_time)\n",
    "            continue\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        status, answer_responce = process_numeric_math(item)\n",
    "        if status:\n",
    "            l_submit_ids.append(id)\n",
    "            l_submit_answers.append(answer_responce)\n",
    "            t2 = time.time()\n",
    "            predicted_time = int(t2*1000 - t1*1000)\n",
    "            l_predicted_time.append(predicted_time)\n",
    "            continue\n",
    "    except:\n",
    "        pass\n",
    "    question = item[\"question\"]\n",
    "    question = question.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    if question[-1] == \":\":\n",
    "        question = question[:-1] + \"?\"\n",
    "    else:\n",
    "        question = question + \"?\"\n",
    "    choices = item[\"choices\"]\n",
    "    cleaned_choices = []\n",
    "    for choice in choices: \n",
    "        if choice != None and len(choice) != 0:\n",
    "            cleaned_choices.append(choice)\n",
    "    choices_str = \"\\n\".join(cleaned_choices)\n",
    "    \n",
    "    prompt = generate_prompt_based_on_train_bm25(current_question = question,\\\n",
    "                                            choices_str=choices_str,\\\n",
    "                                            bm25=bm25_index,\\\n",
    "                                            prefix_prompt=prefix_prompt,\\\n",
    "                                            l_data_with_explanation=l_data_with_explanation,\\\n",
    "                                            num_used=0)\n",
    "    if config[\"USE_MODEL\"]:\n",
    "        inputs = tokenizer([prompt], return_tensors=\"pt\").to('cuda')\n",
    "        res = model.generate(**inputs,  max_new_tokens=200,temperature=0.01)\n",
    "        output = tokenizer.decode(res.cpu()[0], skip_special_tokens=True)\n",
    "        answer_responce = get_final_choices(item, output)\n",
    "        l_submit_ids.append(id)\n",
    "        l_submit_answers.append(answer_responce)\n",
    "    else:\n",
    "        l_submit_ids.append(id)\n",
    "        l_submit_answers.append(item[\"choices\"][0])\n",
    "    t2 = time.time()\n",
    "    predicted_time = int(t2*1000 - t1*1000)\n",
    "    l_predicted_time.append(predicted_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame()\n",
    "df_submit[\"id\"] = l_submit_ids\n",
    "df_submit[\"answer\"] = l_submit_answers\n",
    "if config[\"DELOY_KAGGLE\"]:\n",
    "    df_submit.to_csv(\"/kaggle/working/jupyter_submission.csv\", index = False)\n",
    "else:\n",
    "    if not os.path.exists(\"/result\"):\n",
    "        os.mkdir(\"/result\")\n",
    "    df_submit.to_csv(\"/result/jupyter_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = pd.DataFrame()\n",
    "df_time[\"id\"] = l_submit_ids\n",
    "df_time[\"time\"] = l_predicted_time\n",
    "if config[\"DELOY_KAGGLE\"]:\n",
    "    df_time.to_csv(\"/kaggle/working/time_submission.csv\", index = False)\n",
    "else:\n",
    "    if not os.path.exists(\"/result\"):\n",
    "        os.mkdir(\"/result\")\n",
    "    df_time.to_csv(\"/result/time_submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
